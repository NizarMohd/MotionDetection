{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOj/q+BPxlFbJbREbyMlqEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NizarMohd/RunOrWalk/blob/main/RunOrWalk2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOurYdL_g7gQ"
      },
      "source": [
        "### **1. Preparation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTlLG_bcoO6b"
      },
      "source": [
        "**Check Python version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARv-s-txf3uD",
        "outputId": "b808abdb-58d3-4343-8849-5423a2551d5e"
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFaC1Lhpi7aa"
      },
      "source": [
        "**Check Cuda version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E12NYxEGi6vl",
        "outputId": "470fef28-3f3a-4508-b376-2352e5c711a3"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIxeaFlsjBnE"
      },
      "source": [
        "**Mount the Google drive.**\n",
        "\n",
        "Mount your Google drive to store the dataset and the trained models.\n",
        "Execute the cell below. Visit this [URL](https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code) to retrieve the authorization code and  enter the code at the prompt. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3U1uvTKjDGp",
        "outputId": "c89333e3-dbb4-43ae-fbcc-8316f6e459fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPiZNFfgjY9b"
      },
      "source": [
        "**Create a project directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGmpB48fjbai",
        "outputId": "7b354bb3-71e9-462b-b2e7-0c0696dad306"
      },
      "source": [
        "from os import path, chdir, getcwd, mkdir\n",
        "\n",
        "# Choose a project name\n",
        "projectName = \"RunOrWalk\"\n",
        "\n",
        "# Project directory is in My Drive\n",
        "projectDirectory = \"/content/drive/My Drive/\" + projectName\n",
        "\n",
        "# Checks if cwd is in content folder\n",
        "if getcwd() == \"/content\":\n",
        "  # Makes project directory if it does not exist\n",
        "  if not path.isdir(projectDirectory):\n",
        "    mkdir(projectDirectory)\n",
        "    print(f\"Project {projectName} has been created!\")\n",
        "  else:\n",
        "    print(f\"Project {projectName} already exist!\")\n",
        "  # Changes to project directory\n",
        "  chdir(projectDirectory)\n",
        "\n",
        "print(f\"The current working directory is {getcwd()}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current working directory is /content/drive/My Drive/RunOrWalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLZH9nB2kvAu"
      },
      "source": [
        "**Install dependencies.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OiXRehTkz0G",
        "outputId": "f90b9d37-2e33-4ad3-ee74-7f1f10298955"
      },
      "source": [
        "pip install torch torchvision"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDyP8vkmr4Np",
        "outputId": "bd97bde0-8394-4bba-8764-ee9f7471d68b"
      },
      "source": [
        "pip install opencv-python"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXTyLXUinH7y"
      },
      "source": [
        "**Check GPU usage.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwsnNKtmnRht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70b018b-e367-43ae-f075-c6321b563bc2"
      },
      "source": [
        "# Check if runtime uses GPU\n",
        "import torch\n",
        "\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "\n",
        "print(\"Using GPU\", gpu_name)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "_PH03xCN8O-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and displaying images\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Sampler\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "import tensorflow as tf\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import *\n",
        "\n",
        "\n",
        "datasets = pd.read_csv('features.csv')\n",
        "\n",
        "train_set, test_set = train_test_split(datasets, test_size = 0.1)\n",
        "train_set = train_set.dropna()\n",
        "test_set = test_set.dropna()\n",
        "# # extract labels\n",
        "\n",
        "# def extract_labels(df): \n",
        "#     x_train = [] \n",
        "#     y_train = [] \n",
        " \n",
        "#     i = 0 \n",
        "#     while i + 1 < len(df): \n",
        "#         x_train_point = df[i: i + 1].filter(items=[\"min_ax\", \"min_ay\", \"min_az\", \"min_gx\", \"min_gy\", \"min_gz\", \"max_ax\", \"max_ay\", \"max_az\", \"max_gx\", \"max_gy\", \"max_gz\", \\\n",
        "#           \"avg_ax\", \"avg_ay\", \"avg_az\", \"avg_gx\", \"avg_gy\", \"avg_gz\", \"energy_ax\", \"energy_ay\", \"energy_az\", \"energy_gx\", \"energy_gy\", \"energy_gz\", \"label\"]) \n",
        "#         x_train.append(x_train_point.to_numpy()) \n",
        "#         y_train.append(df['label'].iloc[i]) \n",
        "#         i = i + 1 \n",
        " \n",
        "#     x_train = torch.from_numpy(np.array(x_train))\n",
        "#     y_train = torch.from_numpy(np.array(y_train))\n",
        "     \n",
        "#     return x_train, y_train\n",
        "\n",
        "# train_x, train_y = extract_labels(train_set)\n",
        "# test_x, test_y = extract_labels(test_set)\n",
        "\n",
        "# print(train_x.shape)\n",
        "# print(train_y.shape)\n",
        "# print(test_x.shape)\n",
        "# print(test_y.shape)\n",
        "\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \n",
        "    \n",
        "    def __init__(self, is_train=True):\n",
        "      if is_train:\n",
        "        self.data = train_set\n",
        "      else:\n",
        "        self.data = test_set\n",
        "      print(f'loaded data with dataset size {len(self)}')\n",
        " \n",
        "      \n",
        "    def __getitem__(self, idx):\n",
        "        classes = 2\n",
        "        # print(self.data.iloc[idx])\n",
        "        # sys.stdout.flush()\n",
        "        item = self.data.iloc[idx] \n",
        "        image = item[0:24]\n",
        "        label = item[24]\n",
        "        image = torch.from_numpy(np.array(image))\n",
        "        labels = []\n",
        "        for i in range(classes):\n",
        "            if i == label:\n",
        "              labels.append(1)\n",
        "            else:\n",
        "              labels.append(0)\n",
        "        labels = torch.IntTensor(labels)\n",
        "        return image, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "AzKOWyRg8Oa1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ],
      "metadata": {
        "id": "v2kzMm1wF1G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    n_input = 24\n",
        "    n_h1 = 12 \n",
        "    n_h2 = 6\n",
        "    n_output = 2\n",
        "    self.h1 = nn.Linear(n_input, n_h1)\n",
        "    self.h2 = nn.Linear(n_h1, n_h2)\n",
        "    self.output = nn.Linear(n_h2, n_output)\n",
        "\n",
        "    print(self)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.h1(x))\n",
        "    x = F.relu(self.h2(x))\n",
        "    x = self.output(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# class Net(nn.Module):   \n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(24,12)    # input layer\n",
        "#         self.fc2 = nn.Linear(12, 6)            # hidden layer\n",
        "#         self.out = nn.Linear(6, 2)\n",
        "        \n",
        "\n",
        "#     # Defining the forward pass    \n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.out(x)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "a6ynyLB1FpAH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "KKkuKyMPFyf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def accuracy_score(outputs, targets):\n",
        "  sum = 0\n",
        "  batch_size = targets.size(0)\n",
        "  \n",
        "  for i in range(batch_size):\n",
        "    index_O = outputs.cpu().data.numpy()[i].argmax()\n",
        "    index_T = targets.cpu().data.numpy()[i].argmax()\n",
        "\n",
        "    if index_O == index_T:\n",
        "      sum = sum + 1\n",
        "  return sum / batch_size\n",
        "\n",
        "def train():\n",
        "  batch_size = 64\n",
        "  num_epochs = 30\n",
        "  num_workers = 2\n",
        "\n",
        "  model = Model()\n",
        "  model = model.cuda().float()\n",
        "  \n",
        "  loss_fn = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(),lr = 0.001, momentum= 0.9, nesterov = True)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.3, verbose=True)\n",
        "\n",
        "  train_set = MyDataset(is_train=True)\n",
        "  validation_set = MyDataset(is_train=False)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size, num_workers=num_workers, pin_memory=True, shuffle=True)\n",
        "  validation_loader = torch.utils.data.DataLoader(\n",
        "        validation_set, batch_size=batch_size, num_workers=num_workers, pin_memory=True, shuffle=False)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss, valid_loss = [], []\n",
        "    train_acc , val_acc = [], []\n",
        "    # train\n",
        "    model.train()\n",
        "\n",
        "    # #quantize model\n",
        "    # model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "    # model = torch.quantization.prepare_qat(model, inplace=True)\n",
        " \n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.cuda().float(), target.cuda().float()\n",
        "        # clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward prop\n",
        "        prediction = model(data)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        #backward prop\n",
        "        loss.backward()\n",
        "\n",
        "        ## weight optimization\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        train_acc.append(accuracy_score(prediction, target))\n",
        "\n",
        "        if i % 100 == 99:\n",
        "                print(f'training: iteration {i} / {len(train_loader)}, avg train loss = {np.mean(train_loss):.4f}, '\n",
        "                      f'train accuracy {np.mean(train_acc):.4f}')\n",
        "    \n",
        "    # eval\n",
        "    model.eval()\n",
        "    for i, (data, target) in enumerate(validation_loader):\n",
        "        data, target = data.cuda().float(), target.cuda().float()\n",
        "        prediction = model(data)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        valid_loss.append(loss.item())\n",
        "        val_acc.append(accuracy_score(prediction, target))\n",
        "\n",
        "        if i % 100 == 99:\n",
        "                print(f'validation: iteration {i} / {len(validation_loader)}, avg val loss = {np.mean(train_loss):.4f}, '\n",
        "                      f'val accuracy {val_acc.avg:.4f}')\n",
        " \n",
        "    # epoch summary\n",
        "    print(\"Epoch:\", epoch, \"Train Loss:\", np.mean(train_loss), \"Train acc:\", np.mean(train_acc), \"Val Loss:\", np.mean(valid_loss), \"Val Acc:\",  np.mean(val_acc))\n",
        "\n",
        "    # lr scheduler\n",
        "    scheduler.step(np.mean(valid_loss))\n",
        "\n",
        "    # checkpoint\n",
        "    if epoch % 2 == 1:\n",
        "        torch.save(model.state_dict(), f'ckpt_e{epoch}.pth')\n",
        "    \n",
        "  torch.save(model.state_dict(), 'A0183398M-Model.pth')\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcChwK_6INa9",
        "outputId": "19cf6d79-336a-4f56-d54e-928a885b9e67"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (h1): Linear(in_features=24, out_features=12, bias=True)\n",
            "  (h2): Linear(in_features=12, out_features=6, bias=True)\n",
            "  (output): Linear(in_features=6, out_features=2, bias=True)\n",
            ")\n",
            "loaded data with dataset size 16807\n",
            "loaded data with dataset size 1869\n",
            "training: iteration 99 / 263, avg train loss = 0.1392, train accuracy 0.8584\n",
            "training: iteration 199 / 263, avg train loss = 0.1029, train accuracy 0.8988\n",
            "Epoch: 0 Train Loss: 0.09003125973215802 Train acc: 0.9142704372623575 Val Loss: 0.044935589159528416 Val Acc: 0.9698317307692308\n",
            "training: iteration 99 / 263, avg train loss = 0.0360, train accuracy 0.9762\n",
            "training: iteration 199 / 263, avg train loss = 0.0316, train accuracy 0.9810\n",
            "Epoch: 1 Train Loss: 0.030088414246846742 Train acc: 0.9824144486692015 Val Loss: 0.024768109867970147 Val Acc: 0.9911458333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0226, train accuracy 0.9859\n",
            "training: iteration 199 / 263, avg train loss = 0.0208, train accuracy 0.9895\n",
            "Epoch: 2 Train Loss: 0.020142073272072316 Train acc: 0.9898407794676806 Val Loss: 0.01961646828179558 Val Acc: 0.9927083333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0179, train accuracy 0.9914\n",
            "training: iteration 199 / 263, avg train loss = 0.0174, train accuracy 0.9912\n",
            "Epoch: 3 Train Loss: 0.017111561919771447 Train acc: 0.9915042775665399 Val Loss: 0.01681251870468259 Val Acc: 0.9942708333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0156, train accuracy 0.9930\n",
            "training: iteration 199 / 263, avg train loss = 0.0153, train accuracy 0.9921\n",
            "Epoch: 4 Train Loss: 0.015537787744060103 Train acc: 0.9918607414448669 Val Loss: 0.01549034755056103 Val Acc: 0.9942708333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0153, train accuracy 0.9909\n",
            "training: iteration 199 / 263, avg train loss = 0.0146, train accuracy 0.9917\n",
            "Epoch: 5 Train Loss: 0.014403425656372378 Train acc: 0.9922172053231939 Val Loss: 0.014093647121141355 Val Acc: 0.99375\n",
            "training: iteration 99 / 263, avg train loss = 0.0136, train accuracy 0.9928\n",
            "training: iteration 199 / 263, avg train loss = 0.0134, train accuracy 0.9931\n",
            "Epoch: 6 Train Loss: 0.013539396863813183 Train acc: 0.9927732280393878 Val Loss: 0.01322174610880514 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0137, train accuracy 0.9911\n",
            "training: iteration 199 / 263, avg train loss = 0.0130, train accuracy 0.9920\n",
            "Epoch: 7 Train Loss: 0.012873672791703572 Train acc: 0.9926330798479087 Val Loss: 0.013160714584713181 Val Acc: 0.9942708333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0124, train accuracy 0.9928\n",
            "training: iteration 199 / 263, avg train loss = 0.0124, train accuracy 0.9930\n",
            "Epoch: 8 Train Loss: 0.012239291436240756 Train acc: 0.9933460076045627 Val Loss: 0.011914007365703583 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0115, train accuracy 0.9944\n",
            "training: iteration 199 / 263, avg train loss = 0.0114, train accuracy 0.9940\n",
            "Epoch: 9 Train Loss: 0.011727450312798694 Train acc: 0.9934054182509505 Val Loss: 0.011856326383228104 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0119, train accuracy 0.9928\n",
            "training: iteration 199 / 263, avg train loss = 0.0113, train accuracy 0.9937\n",
            "Epoch: 10 Train Loss: 0.011239498109156585 Train acc: 0.9938807034220533 Val Loss: 0.010840929322876036 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0116, train accuracy 0.9933\n",
            "training: iteration 199 / 263, avg train loss = 0.0107, train accuracy 0.9943\n",
            "Epoch: 11 Train Loss: 0.010820527359163353 Train acc: 0.9940589353612167 Val Loss: 0.010340278595685959 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0109, train accuracy 0.9934\n",
            "training: iteration 199 / 263, avg train loss = 0.0106, train accuracy 0.9938\n",
            "Epoch: 12 Train Loss: 0.010471036247802835 Train acc: 0.9937237983815932 Val Loss: 0.009724122759265205 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0098, train accuracy 0.9945\n",
            "training: iteration 199 / 263, avg train loss = 0.0100, train accuracy 0.9941\n",
            "Epoch: 13 Train Loss: 0.010119185304913684 Train acc: 0.9939614409671446 Val Loss: 0.009406249783933163 Val Acc: 0.9947916666666666\n",
            "training: iteration 99 / 263, avg train loss = 0.0097, train accuracy 0.9950\n",
            "training: iteration 199 / 263, avg train loss = 0.0098, train accuracy 0.9942\n",
            "Epoch: 14 Train Loss: 0.009755688151096776 Train acc: 0.9942371673003803 Val Loss: 0.00917953901613752 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0099, train accuracy 0.9933\n",
            "training: iteration 199 / 263, avg train loss = 0.0098, train accuracy 0.9938\n",
            "Epoch: 15 Train Loss: 0.00948961105148092 Train acc: 0.9942371673003803 Val Loss: 0.008777067779252927 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0097, train accuracy 0.9936\n",
            "training: iteration 199 / 263, avg train loss = 0.0093, train accuracy 0.9945\n",
            "Epoch: 16 Train Loss: 0.00927378982571113 Train acc: 0.9943179048454716 Val Loss: 0.008476391201838851 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0091, train accuracy 0.9945\n",
            "training: iteration 199 / 263, avg train loss = 0.0092, train accuracy 0.9943\n",
            "Epoch: 17 Train Loss: 0.008988526316019688 Train acc: 0.9945936311787072 Val Loss: 0.008299709693528712 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0090, train accuracy 0.9942\n",
            "training: iteration 199 / 263, avg train loss = 0.0089, train accuracy 0.9945\n",
            "Epoch: 18 Train Loss: 0.00876060690989314 Train acc: 0.9946149580774106 Val Loss: 0.00800120491379251 Val Acc: 0.9958333333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0085, train accuracy 0.9952\n",
            "training: iteration 199 / 263, avg train loss = 0.0084, train accuracy 0.9953\n",
            "Epoch: 19 Train Loss: 0.00855890279919079 Train acc: 0.9949714219557376 Val Loss: 0.007738767921303709 Val Acc: 0.9958333333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0083, train accuracy 0.9950\n",
            "training: iteration 199 / 263, avg train loss = 0.0083, train accuracy 0.9949\n",
            "Epoch: 20 Train Loss: 0.008318771172612338 Train acc: 0.9949500950570342 Val Loss: 0.007463636357958118 Val Acc: 0.9958333333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0074, train accuracy 0.9958\n",
            "training: iteration 199 / 263, avg train loss = 0.0079, train accuracy 0.9954\n",
            "Epoch: 21 Train Loss: 0.008090697237761416 Train acc: 0.9948906844106464 Val Loss: 0.0074169342018043 Val Acc: 0.9958333333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0078, train accuracy 0.9955\n",
            "training: iteration 199 / 263, avg train loss = 0.0079, train accuracy 0.9953\n",
            "Epoch: 22 Train Loss: 0.007947503990128977 Train acc: 0.9951496538949012 Val Loss: 0.007347112389591833 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0072, train accuracy 0.9956\n",
            "training: iteration 199 / 263, avg train loss = 0.0077, train accuracy 0.9950\n",
            "Epoch: 23 Train Loss: 0.0077315013082839635 Train acc: 0.9950095057034221 Val Loss: 0.007223691989202053 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0078, train accuracy 0.9942\n",
            "training: iteration 199 / 263, avg train loss = 0.0077, train accuracy 0.9945\n",
            "Epoch: 24 Train Loss: 0.007582506332227769 Train acc: 0.9951283269961977 Val Loss: 0.006765178164156774 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0074, train accuracy 0.9944\n",
            "training: iteration 199 / 263, avg train loss = 0.0074, train accuracy 0.9948\n",
            "Epoch: 25 Train Loss: 0.007414237192846098 Train acc: 0.9949500950570342 Val Loss: 0.006608265405520797 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0077, train accuracy 0.9944\n",
            "training: iteration 199 / 263, avg train loss = 0.0072, train accuracy 0.9950\n",
            "Epoch: 26 Train Loss: 0.0072827302512603 Train acc: 0.9950902432485134 Val Loss: 0.006434187401706973 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0075, train accuracy 0.9948\n",
            "training: iteration 199 / 263, avg train loss = 0.0070, train accuracy 0.9955\n",
            "Epoch: 27 Train Loss: 0.00712520051782972 Train acc: 0.9951283269961977 Val Loss: 0.006863019491235415 Val Acc: 0.9953125\n",
            "training: iteration 99 / 263, avg train loss = 0.0076, train accuracy 0.9939\n",
            "training: iteration 199 / 263, avg train loss = 0.0072, train accuracy 0.9947\n",
            "Epoch: 28 Train Loss: 0.0069778165881815915 Train acc: 0.9950095057034221 Val Loss: 0.006201330184315641 Val Acc: 0.9958333333333333\n",
            "training: iteration 99 / 263, avg train loss = 0.0067, train accuracy 0.9953\n",
            "training: iteration 199 / 263, avg train loss = 0.0068, train accuracy 0.9952\n",
            "Epoch: 29 Train Loss: 0.006862295441375514 Train acc: 0.9951283269961977 Val Loss: 0.006105183763429523 Val Acc: 0.9958333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Accuracy"
      ],
      "metadata": {
        "id": "0eEU6RVkW7ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.container import ModuleList\n",
        "import torch\n",
        "from torch import nn\n",
        "# Change [your_python_file] to the actual file containing the definitons of the classes\n",
        "\n",
        "\n",
        "def test():\n",
        "    my_model = Model()\n",
        "    my_model = my_model.cuda()\n",
        "    my_model.eval()\n",
        "\n",
        "    my_model.load_state_dict(torch.load('A0183398M-Model.pth'))\n",
        "    \n",
        "    \n",
        "    test_set = MyDataset(is_train=False)\n",
        "    batch_size = 64\n",
        "\n",
        "\n",
        "    # mp.set_start_method('spawn', force=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \\\n",
        "                      shuffle=False)\n",
        "\n",
        "    # test accuracy\n",
        "    test_acc = []\n",
        "    for i, (image,label) in enumerate(test_loader):\n",
        "        image, label = image.cuda().float(), label.cuda().float()\n",
        "        with torch.no_grad():\n",
        "            prediction = my_model(image)\n",
        "            acc = accuracy_score(prediction, label)\n",
        "            test_acc.append(acc)\n",
        "\n",
        "        if i % 10 == 9:\n",
        "            print(f'test: iteration {i} / {len(test_loader)}, '\n",
        "                  f'test accuracy {np.mean(test_acc):.4f}')\n",
        "\n",
        "    print(f'evaluation finished, val acc {np.mean(test_acc):.4f}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDBsYHmGW3nh",
        "outputId": "7f0d0a3d-287f-457e-e403-e77c4ffe5801"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (h1): Linear(in_features=24, out_features=12, bias=True)\n",
            "  (h2): Linear(in_features=12, out_features=6, bias=True)\n",
            "  (output): Linear(in_features=6, out_features=2, bias=True)\n",
            ")\n",
            "loaded data with dataset size 1869\n",
            "test: iteration 9 / 30, test accuracy 0.9953\n",
            "test: iteration 19 / 30, test accuracy 0.9961\n",
            "test: iteration 29 / 30, test accuracy 0.9958\n",
            "evaluation finished, val acc 0.9958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract weights and biases"
      ],
      "metadata": {
        "id": "tCgVxk5bqyuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import torch.quantization.quantize_fx as quantize_fx\n",
        "import copy\n",
        "import csv\n",
        "\n",
        "my_model = Model()\n",
        "my_model = my_model.cuda()\n",
        "my_model.eval()\n",
        "my_model.load_state_dict(torch.load('A0183398M-Model.pth'))\n",
        "f = open('/content/drive/MyDrive/RunOrWalk/weights.csv', 'w', encoding='UTF8', newline='')\n",
        "writer = csv.writer(f)\n",
        "\n",
        "w1 = []\n",
        "w2 = []\n",
        "w3 = []\n",
        "\n",
        "b1 = []\n",
        "b2 = []\n",
        "b3 = []\n",
        "\n",
        "\n",
        "\n",
        "for param_tensor in my_model.state_dict():\n",
        "    # get each layer, print layer size\n",
        "    print(param_tensor, \"\\t\", my_model.state_dict()[param_tensor].size())\n",
        "    print(\"\\n\")\n",
        "    print(param_tensor, \"\\t\", my_model.state_dict()[param_tensor])\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # prepare min,max of each layer\n",
        "    r_max = 0\n",
        "    r_min = 0\n",
        "    layer = my_model.state_dict()[param_tensor]\n",
        "\n",
        "    \n",
        "    # if param_tensor == 'h1.weight' or param_tensor == 'h2.weight' or param_tensor == 'output.weight':\n",
        "    #   # writer.writerow(\"weights\")\n",
        "    #   print(\"weights\")\n",
        "    #   #layer is 2D array\n",
        "    #   for row in layer:\n",
        "    #     if r_max < max(row.cpu().numpy()):\n",
        "    #       r_max = max(row.cpu().numpy())      \n",
        "    #     if r_min > min(row.cpu().numpy()):\n",
        "    #       r_min = min(row.cpu().numpy())\n",
        "    # else:\n",
        "    #   # layer is 1D array\n",
        "    #   # writer.writerow(\"bias\")\n",
        "    #   print(\"bias\")\n",
        "    #   r_max = max(layer.cpu().numpy())\n",
        "    #   r_min = min(layer.cpu().numpy())\n",
        "\n",
        "    # s = 2 / (r_max - r_min)\n",
        "    # c = -1 - s * r_min\n",
        "    out = []\n",
        "\n",
        "    \n",
        "    r = 0\n",
        "  \n",
        "\n",
        "    if param_tensor == 'h1.weight' or param_tensor == 'h2.weight' or param_tensor == 'output.weight':\n",
        "      #layer is 2D array\n",
        "      for row in layer:\n",
        "        r = r + 1\n",
        "        for item in row:\n",
        "          y = item.item() * (10**3)\n",
        "          out.append(round(y))\n",
        "          if param_tensor == 'h1.weight':\n",
        "            w1.append(round(y))\n",
        "          elif param_tensor == 'h2.weight':\n",
        "            w2.append(round(y))\n",
        "          else:\n",
        "            w3.append(round(y))\n",
        "\n",
        "      \n",
        "    else:\n",
        "      # layer is 1D array\n",
        "      for item in layer:\n",
        "          r = r + 1\n",
        "          y = item.item() * (10**3)\n",
        "          \n",
        "          out.append(round(y))\n",
        "          if param_tensor == 'h1.bias':\n",
        "            b1.append(round(y))\n",
        "          elif param_tensor == 'h2.bias':\n",
        "            b2.append(round(y))\n",
        "          else:\n",
        "            b3.append(round(y))\n",
        "\n",
        "    print(r)\n",
        "    print(out)\n",
        "    \n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "#  compute accuracy of quantized weights\n",
        "\n",
        "\n",
        "test_set = MyDataset(is_train=False)\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# mp.set_start_method('spawn', force=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \\\n",
        "                  shuffle=False)\n",
        "\n",
        "# test accuracy\n",
        "test_acc = []\n",
        "\n",
        "for k, (image,label) in enumerate(test_loader):\n",
        "        \n",
        "        acc = 0\n",
        "        idx = 0\n",
        "        preds = []\n",
        "        for data in image:\n",
        "          z1 = []\n",
        "          z2 = []\n",
        "          z3 = []\n",
        "          # 24 attr, 64 data\n",
        "          # compute Z1 = W1x + b1\n",
        "          j = 0\n",
        "          z = 0\n",
        "          x = data.numpy()\n",
        "          for i in range(0, 288):\n",
        "            z = w1[i] * x[i%24] + z\n",
        "            if i% 24 == 23:\n",
        "              z = z + b1[j]\n",
        "              j = j + 1\n",
        "              if z < 0:\n",
        "                z = 0\n",
        "              z1. append(round(z/1000))\n",
        "              z = 0\n",
        "          \n",
        "\n",
        "          # compute z2 = w2 * z1 + b2\n",
        "          j = 0\n",
        "          z = 0\n",
        "          for i in range(0, 72):\n",
        "            z = w2[i] * z1[i%12] + z\n",
        "            if i% 12 == 11:\n",
        "              z = z + b2[j]\n",
        "              j = j + 1\n",
        "              if z < 0:\n",
        "                z = 0\n",
        "              z2. append(round(z/1000))\n",
        "              z = 0 \n",
        "          \n",
        "\n",
        "          # compute z3 = w3z2 + b2\n",
        "          j = 0\n",
        "          z = 0\n",
        "          for i in range(0, 12):\n",
        "            z = w3[i] * z2[i%6] + z\n",
        "            if i% 6 == 5:\n",
        "              z = z + b3[j]\n",
        "              j = j + 1\n",
        "              z3. append(z)\n",
        "              z = 0\n",
        "          \n",
        "        \n",
        "          pred = np.argmax(np.asarray(z3))\n",
        "          preds.append(pred)\n",
        "\n",
        "        sum = 0\n",
        "        for i in range(label.size(0)):\n",
        "          i_o = preds[i]\n",
        "          i_t = np.argmax(label[i].numpy())\n",
        "          if i_o == i_t:\n",
        "            sum = sum + 1\n",
        "        test_acc.append(acc/label.size(0))\n",
        "        print(sum/label.size(0))\n",
        "\n",
        "print(np.mean(test_acc))  \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_I2HLqbqxs5",
        "outputId": "71c1dc91-9fae-4af1-dfdf-7993d45d0947"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (h1): Linear(in_features=24, out_features=12, bias=True)\n",
            "  (h2): Linear(in_features=12, out_features=6, bias=True)\n",
            "  (output): Linear(in_features=6, out_features=2, bias=True)\n",
            ")\n",
            "h1.weight \t torch.Size([12, 24])\n",
            "\n",
            "\n",
            "h1.weight \t tensor([[ 1.1506e-01,  1.3441e-01, -2.6631e-02, -4.6613e-02, -1.2313e-01,\n",
            "          5.8204e-02, -5.8045e-02, -2.8568e-02,  8.0751e-02, -1.5330e-01,\n",
            "         -1.0259e-01,  1.4188e-01, -1.1627e-01, -1.2526e-01,  7.4990e-02,\n",
            "          1.4217e-01, -1.9462e-01,  1.6400e-01, -1.2933e-01, -1.3758e-01,\n",
            "          4.9228e-02, -1.0618e-01, -2.0152e-01, -2.6965e-02],\n",
            "        [-1.6187e-01,  8.8895e-02,  2.0653e-01,  1.3889e-01,  7.6473e-02,\n",
            "          1.4013e-01,  6.9450e-02,  1.1800e-01,  1.5020e-01, -5.6644e-02,\n",
            "         -6.1516e-02, -2.8601e-02, -4.3682e-02, -2.1429e-01, -1.5407e-01,\n",
            "         -1.4786e-01,  1.5407e-01, -1.7131e-01, -5.7463e-02,  1.1162e-01,\n",
            "         -2.3938e-01, -7.6743e-02,  1.1809e-01,  1.4307e-01],\n",
            "        [ 1.7483e-02,  1.3818e-01, -3.7618e-03, -5.5580e-02,  1.4634e-01,\n",
            "         -4.7728e-02,  1.6673e-01, -1.9164e-01,  1.2224e-01,  2.3045e-02,\n",
            "          1.4681e-02, -1.3892e-01,  1.1156e-01, -4.0504e-02,  1.4492e-02,\n",
            "          1.5548e-01,  1.4348e-01, -1.6426e-01, -1.9971e-01,  9.9975e-02,\n",
            "          4.6409e-02,  4.1700e-02, -4.8163e-02, -7.2590e-03],\n",
            "        [-1.9980e-02, -5.2000e-02, -1.5194e-01, -5.5910e-02,  1.3217e-01,\n",
            "         -1.6729e-01, -5.8975e-02, -1.2193e-01, -3.6644e-02, -5.6881e-02,\n",
            "         -6.2316e-05,  8.7042e-02,  7.2253e-02,  1.4588e-01,  4.5787e-02,\n",
            "         -7.8799e-03, -7.9513e-02,  1.0184e-01,  2.5293e-01, -9.3429e-02,\n",
            "          3.1898e-02,  9.9287e-04,  7.4331e-03,  2.3683e-02],\n",
            "        [ 1.5793e-03, -3.6055e-02,  1.4534e-01,  2.5883e-02, -4.7815e-02,\n",
            "         -1.2868e-01, -4.8136e-02, -1.3858e-01,  6.2779e-02, -3.8102e-02,\n",
            "         -4.7957e-02,  1.4378e-01,  1.4058e-01, -7.0806e-02,  1.5496e-01,\n",
            "          7.2084e-02, -6.0175e-02, -1.2631e-02, -3.1613e-01,  3.5391e-01,\n",
            "         -1.8684e-01, -2.7691e-02, -1.3524e-03, -4.2024e-02],\n",
            "        [ 1.6057e-01, -8.7861e-02, -7.0806e-02,  2.3005e-02,  4.9938e-02,\n",
            "          1.2990e-01,  8.5585e-03,  2.1691e-02, -9.3216e-02,  1.1272e-02,\n",
            "          9.9055e-04, -4.5297e-03, -1.3309e-01, -1.9315e-01,  7.9826e-02,\n",
            "          1.5335e-01,  1.9478e-01, -1.2596e-01, -1.3376e-01,  2.7009e-01,\n",
            "         -2.2722e-01, -3.2074e-02, -3.1012e-02,  1.4267e-01],\n",
            "        [ 1.0058e-01,  2.2524e-01, -1.1734e-01,  2.2003e-01, -2.8581e-02,\n",
            "         -2.0017e-02,  5.4027e-02,  1.8693e-01,  7.0539e-02,  4.3363e-02,\n",
            "          1.0545e-01, -2.2116e-02, -7.9221e-02,  7.2582e-02, -1.0705e-01,\n",
            "          9.6293e-02, -6.1955e-02,  1.4796e-01, -1.3874e-01,  4.7869e-02,\n",
            "          4.7892e-02,  1.8968e-02,  2.9059e-02,  3.9700e-03],\n",
            "        [-5.0711e-02, -9.0164e-02,  1.4257e-01,  1.2427e-01,  1.6078e-01,\n",
            "          8.0366e-02,  2.2543e-01, -5.1349e-02,  2.2722e-01, -4.4814e-02,\n",
            "         -2.8608e-02, -1.4475e-01, -2.4055e-02,  6.1422e-02,  2.2846e-01,\n",
            "         -1.4743e-01, -4.1375e-02,  1.7614e-01, -4.8113e-02, -2.7953e-02,\n",
            "         -1.3034e-01,  8.9011e-02,  4.8347e-02,  7.5638e-02],\n",
            "        [-1.9579e-02,  1.8207e-01,  9.9759e-02, -6.5710e-02,  1.6806e-01,\n",
            "          3.3360e-02,  1.6298e-01,  1.9981e-01, -7.4540e-02, -3.8006e-02,\n",
            "         -1.1246e-01, -6.3966e-02, -9.0391e-02,  3.5813e-01,  1.4492e-01,\n",
            "         -4.8820e-02,  9.3736e-02, -6.6071e-02,  1.6561e-01, -1.0372e-01,\n",
            "          1.3147e-01, -1.0373e-01, -2.5309e-02,  1.6492e-01],\n",
            "        [ 2.1180e-01,  1.3573e-01,  2.6267e-01, -2.5083e-02, -1.9834e-03,\n",
            "         -2.0014e-02,  9.1516e-02,  3.7725e-02,  7.9447e-02,  1.6942e-01,\n",
            "          9.1037e-02,  8.6804e-03,  1.1742e-01, -1.1546e-01,  2.3559e-01,\n",
            "          9.3024e-02,  1.2486e-02,  2.0535e-01,  6.1349e-02,  3.6880e-02,\n",
            "          1.0951e-02,  5.2516e-03, -7.1913e-02, -1.1437e-01],\n",
            "        [ 1.0795e-01,  1.9338e-01,  5.1668e-02,  9.5870e-02, -6.0001e-02,\n",
            "         -5.9358e-02, -1.7628e-01, -4.2148e-02, -7.7108e-02, -1.0685e-01,\n",
            "          4.8449e-02, -7.7507e-03,  1.6737e-01,  1.6630e-01, -1.7541e-01,\n",
            "         -1.2379e-01,  1.5327e-01, -1.6598e-01,  1.6528e-01, -9.7487e-02,\n",
            "          1.6116e-01, -6.2630e-02,  6.0692e-02, -1.6406e-01],\n",
            "        [-1.2002e-01,  8.5982e-02, -9.9475e-02,  1.3078e-01,  3.4470e-02,\n",
            "          3.2640e-03,  6.7631e-02,  1.2144e-01,  3.4812e-02, -7.7805e-02,\n",
            "         -4.4915e-02,  1.0431e-01, -1.6682e-01, -4.5373e-04,  1.2677e-01,\n",
            "         -4.7573e-02,  1.7414e-03, -1.1930e-02,  1.2264e-01,  1.0550e-01,\n",
            "          4.4656e-02,  1.6710e-01,  1.4779e-02, -9.0856e-02]], device='cuda:0')\n",
            "\n",
            "\n",
            "12\n",
            "[115, 134, -27, -47, -123, 58, -58, -29, 81, -153, -103, 142, -116, -125, 75, 142, -195, 164, -129, -138, 49, -106, -202, -27, -162, 89, 207, 139, 76, 140, 69, 118, 150, -57, -62, -29, -44, -214, -154, -148, 154, -171, -57, 112, -239, -77, 118, 143, 17, 138, -4, -56, 146, -48, 167, -192, 122, 23, 15, -139, 112, -41, 14, 155, 143, -164, -200, 100, 46, 42, -48, -7, -20, -52, -152, -56, 132, -167, -59, -122, -37, -57, 0, 87, 72, 146, 46, -8, -80, 102, 253, -93, 32, 1, 7, 24, 2, -36, 145, 26, -48, -129, -48, -139, 63, -38, -48, 144, 141, -71, 155, 72, -60, -13, -316, 354, -187, -28, -1, -42, 161, -88, -71, 23, 50, 130, 9, 22, -93, 11, 1, -5, -133, -193, 80, 153, 195, -126, -134, 270, -227, -32, -31, 143, 101, 225, -117, 220, -29, -20, 54, 187, 71, 43, 105, -22, -79, 73, -107, 96, -62, 148, -139, 48, 48, 19, 29, 4, -51, -90, 143, 124, 161, 80, 225, -51, 227, -45, -29, -145, -24, 61, 228, -147, -41, 176, -48, -28, -130, 89, 48, 76, -20, 182, 100, -66, 168, 33, 163, 200, -75, -38, -112, -64, -90, 358, 145, -49, 94, -66, 166, -104, 131, -104, -25, 165, 212, 136, 263, -25, -2, -20, 92, 38, 79, 169, 91, 9, 117, -115, 236, 93, 12, 205, 61, 37, 11, 5, -72, -114, 108, 193, 52, 96, -60, -59, -176, -42, -77, -107, 48, -8, 167, 166, -175, -124, 153, -166, 165, -97, 161, -63, 61, -164, -120, 86, -99, 131, 34, 3, 68, 121, 35, -78, -45, 104, -167, 0, 127, -48, 2, -12, 123, 106, 45, 167, 15, -91]\n",
            "\n",
            "\n",
            "h1.bias \t torch.Size([12])\n",
            "\n",
            "\n",
            "h1.bias \t tensor([ 0.1049,  0.0792, -0.0250, -0.1269,  0.1563, -0.0693,  0.1062,  0.1550,\n",
            "         0.1568, -0.0913, -0.0987, -0.1697], device='cuda:0')\n",
            "\n",
            "\n",
            "12\n",
            "[105, 79, -25, -127, 156, -69, 106, 155, 157, -91, -99, -170]\n",
            "\n",
            "\n",
            "h2.weight \t torch.Size([6, 12])\n",
            "\n",
            "\n",
            "h2.weight \t tensor([[ 0.1128, -0.0114,  0.0110, -0.1868, -0.0873,  0.1877, -0.1662, -0.0837,\n",
            "          0.0226,  0.0569, -0.2098,  0.0362],\n",
            "        [-0.0397, -0.2278, -0.2068, -0.0088,  0.2137, -0.2481, -0.2396, -0.2011,\n",
            "         -0.2032, -0.2827, -0.0386, -0.0086],\n",
            "        [ 0.1132,  0.1031,  0.0072, -0.0646,  0.2303, -0.1089,  0.2683,  0.0760,\n",
            "          0.1832,  0.2337, -0.2216,  0.1636],\n",
            "        [-0.0153,  0.1231, -0.0087, -0.3117,  0.1974,  0.1754, -0.2709,  0.2753,\n",
            "         -0.2638,  0.2337, -0.0199, -0.2546],\n",
            "        [ 0.2396,  0.0062, -0.0777, -0.1659, -0.3817, -0.1404, -0.0257,  0.0851,\n",
            "          0.1448,  0.0114,  0.0918,  0.0732],\n",
            "        [-0.2035, -0.1427, -0.1500, -0.1554, -0.3383,  0.1105,  0.1265,  0.0487,\n",
            "         -0.0110,  0.0119, -0.0959, -0.1628]], device='cuda:0')\n",
            "\n",
            "\n",
            "6\n",
            "[113, -11, 11, -187, -87, 188, -166, -84, 23, 57, -210, 36, -40, -228, -207, -9, 214, -248, -240, -201, -203, -283, -39, -9, 113, 103, 7, -65, 230, -109, 268, 76, 183, 234, -222, 164, -15, 123, -9, -312, 197, 175, -271, 275, -264, 234, -20, -255, 240, 6, -78, -166, -382, -140, -26, 85, 145, 11, 92, 73, -203, -143, -150, -155, -338, 111, 127, 49, -11, 12, -96, -163]\n",
            "\n",
            "\n",
            "h2.bias \t torch.Size([6])\n",
            "\n",
            "\n",
            "h2.bias \t tensor([-0.1794, -0.0974,  0.0334, -0.2272,  0.1050,  0.1796], device='cuda:0')\n",
            "\n",
            "\n",
            "6\n",
            "[-179, -97, 33, -227, 105, 180]\n",
            "\n",
            "\n",
            "output.weight \t torch.Size([2, 6])\n",
            "\n",
            "\n",
            "output.weight \t tensor([[-0.3593,  0.0909,  0.1041,  0.3487, -0.3662, -0.1737],\n",
            "        [-0.4043, -0.3939,  0.1075, -0.3554,  0.3423,  0.2995]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "2\n",
            "[-359, 91, 104, 349, -366, -174, -404, -394, 108, -355, 342, 299]\n",
            "\n",
            "\n",
            "output.bias \t torch.Size([2])\n",
            "\n",
            "\n",
            "output.bias \t tensor([0.0161, 0.0385], device='cuda:0')\n",
            "\n",
            "\n",
            "2\n",
            "[16, 39]\n",
            "\n",
            "\n",
            "loaded data with dataset size 1869\n",
            "1.0\n",
            "0.984375\n",
            "0.984375\n",
            "1.0\n",
            "1.0\n",
            "0.984375\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.984375\n",
            "1.0\n",
            "0.984375\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.984375\n",
            "0.984375\n",
            "0.984375\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.984375\n",
            "0.984375\n",
            "0.984375\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q hls4ml"
      ],
      "metadata": {
        "id": "rGBpoBzfm46W"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hls4ml"
      ],
      "metadata": {
        "id": "_r0TYouAm_Tc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = hls4ml.utils.config_from_pytorch_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "wwdNJR5PnDmn",
        "outputId": "8a910cca-a686-411e-9235-6fdb43f97bea"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d3f82a97e1bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhls4ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_from_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}